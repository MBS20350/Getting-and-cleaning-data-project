---
title: "README"
author: "Mark Sucato"
date: "4/19/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This README file discusses the associated run_analysis.R script.  For more information about the HAR dataset as it pertains to this project, please see the provided Codebook.RMD file.

The five tasks of this project are:

1.  Merge the training and test sets to create one data set
2.  Extract only the measurements on the mean and standard deviation for each measurement
3.  Use descriptive activity names to name the activities within the data set
4.  Appropriately label the data set with descriptive variable names
5.  Create a second independent tidy data set with the average of each variable for each activity and subject

## Script Description

The run_analysis.R script uses the dplyr package and assumes the UCI HAR Dataset folder is saved in current working directory.  The script is internally notated by task.  The command source("run_analysis.R") will perform the five tasks, to include saving a file "getting_and_cleaning_data_project_task5.txt" within the working directory.

The script loads both training and test data sets into 'train' and 'test' respectively, and renames the feature variable columns with the names from the "features.txt" file.  This partially completes Tasks 1 and 4.  Task 4 was partially completed out of order in the interests of simplicity at a cost of one potentially extraneous line of code.

```{r}
library(dplyr)
current <- getwd()

setwd("UCI HAR Dataset")    
activ_key <-read.table("activity_labels.txt")
data_labels <- read.table("features.txt")

setwd("./train")    
train_data <- read.table("X_train.txt")
colnames(train_data) <- data_labels$V2
train <- bind_cols(read.table("subject_train.txt"), read.table("y_train.txt"), train_data)

setwd("../test")    
test_data <- read.table("X_test.txt")
colnames(test_data) <- data_labels$V2
test <- bind_cols(read.table("subject_test.txt"), read.table("y_test.txt"), test_data)
setwd(current)    
```

Tasks 1, 3 and 4 were completed by combining 'train' and 'test' into 'data', renaming the subject_ID and activity columns with more descriptive names than before, and recoding the activity identifiers with the actual activities taken from 'activity_labels.txt' As before, the order of tasks was driven by simplicity.

```{r}
data <- bind_rows(train, test)
data <- data %>%
  rename(subject_ID = V1...1) %>%
  rename(activity = V1...2)
data$activity <- recode(data$activity, "walking", "walking_upstairs", "walking_downstairs", "sitting", "standing", "laying")
```

Task 2 was completed by parsing the combined data set for all variables using the terminology 'mean' and 'std.'  This also produced the final data set 'task1_to_4' for Tasks 1-4.  Because the future analysis to be performed on this data set remains unknown, this script intentionally captures all variables potentially associated with means or standard deviations except those obviously associated with angular calculations.  If the future analysis requires a more narrow interpretation of mean or standard variation, it is a simple task to ignore or remove the excess data.  It is easier to later subtract than to later add.

```{r}
task1_to_4 <- data %>%
  select(subject_ID, activity, contains("mean") & !(contains("angle") | contains("Freq")), contains("std"))
```

Lastly, the script creates a second Tidy data set 'task5' with the average of each variable for each activity and each subject.  This new data set is tidy because every column is a variable, every row is an observation and every cell is a single value.

```{r}

task5 <- task1_to_4 %>%
  group_by(subject_ID, activity) %>%
  summarise(across("tBodyAcc-mean()-X":"fBodyBodyGyroJerkMag-std()", mean))

write.table(task5, file = "getting_and_cleaning_data_project_task5.txt", row.name = FALSE)
```


